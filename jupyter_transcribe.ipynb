{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import time # for delay\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from os import listdir\n",
    "from wit import Wit\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# wit.ai token api\n",
    "access_token = 'Enter Wit.AI token Here'\n",
    "access_token = 'NZ53DR2SUADO2PBLJONJI3H4OZZDB3AD'\n",
    "\n",
    "client = Wit(access_token)\n",
    "\n",
    "# get list of file in input folder\n",
    "path_input = os.getcwd() + os.sep +  'input'\n",
    "path_output = os.getcwd() + os.sep +  'output'\n",
    "\n",
    "list = os.listdir(path_input)\n",
    "if len(list) < 1 :\n",
    "    print('No files to transcribe!')\n",
    "    sys.exit()\n",
    "\n",
    "# list of file in input folder\n",
    "print('\\nSelect file to transcribe: ')\n",
    "for i in range(len(list)):\n",
    "    print(str(i) + ' : ' + list[i])\n",
    "\n",
    "#get input from user\n",
    "file = int(input())\n",
    "\n",
    "file = list[file]\n",
    "\n",
    "# get audiofile into usable form\n",
    "audio = AudioSegment.from_file(os.path.join(path_input, str(file)))\n",
    "offset = 15000 # 15000 == 15 seconds -- calculate in millisecond\n",
    "\n",
    "# initialize recognizer\n",
    "r = sr.Recognizer()\n",
    "print('\\nSelect platform for transcribing: \\n0 : Google\\n1 : Wit.AI')\n",
    "\n",
    "# select APIs to use\n",
    "method = int(input())\n",
    "\n",
    "languages = ['en-US', 'it-IT']\n",
    "print('\\nSelect language transcribing: \\n0 : English\\n1 : Italian')\n",
    "language = int(input())\n",
    "language = languages[language]\n",
    "\n",
    "parts = 1 + (len(audio) // offset)\n",
    "for j in range(parts):\n",
    "    # get intervals of 15 from audio data\n",
    "    t1 = j * offset\n",
    "    t2 = t1 + offset\n",
    "    audio_segment = audio[t1:t2 + 1000]\n",
    "\n",
    "    audio_segment.export(os.path.join(path_input, 'temporary.wav') , format=\"wav\")\n",
    "\n",
    "    start = str(datetime.timedelta(seconds=t1 / 1000))\n",
    "    end = str(datetime.timedelta(seconds=t2 / 1000))\n",
    "    print('Part {} of {} \\t [ {}s : {}s ]'.format(j+1,parts, start,end ))\n",
    "    if method == 0:\n",
    "        try:\n",
    "            with sr.AudioFile( os.path.join(path_input, 'temporary.wav')) as source:\n",
    "                aux = r.record(source)  # read the entire audio file\n",
    "\n",
    "            # call to google APIs\n",
    "            data = r.recognize_google(aux, language=language, show_all=False) # English\n",
    "\n",
    "            file_object = open(os.path.join(path_output, file) + '_google.txt' , 'a')\n",
    "            file_object.write('\\n[ ' + str(datetime.timedelta(seconds=t1 / 1000)) + 's : ' + str(datetime.timedelta(seconds=t2 / 1000)) + 's ]\\n')\n",
    "            if str(data)[-1] == ' ':\n",
    "                file_object.write(str(data))\n",
    "            else:\n",
    "                file_object.write(str(data) + ' ')\n",
    "            file_object.close()\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    # 1 = Wit.AI\n",
    "    elif method == 1:\n",
    "        with open(os.path.join(path_input, 'temporary.wav'), 'rb') as f:\n",
    "            # call to Wit.AI APIs\n",
    "            resp = client.speech(f, {'Content-Type': 'audio/wav'})\n",
    "\n",
    "        file_object = open(os.path.join(path_output, file + '_witAI.txt') , 'a')\n",
    "        file_object.write('\\n[ ' + str(datetime.timedelta(seconds=t1 / 1000)) + 's : ' + str(datetime.timedelta(seconds=t2 / 1000)) + 's ]\\n')\n",
    "        if str(resp['text'])[-1] == ' ':\n",
    "            file_object.write(str(resp['text']))\n",
    "        else:\n",
    "            file_object.write(str(resp['text']) + ' ')\n",
    "        file_object.close()\n",
    "\n",
    "    #delete aux files of 15 seconds\n",
    "    os.remove(os.path.join(path_input, 'temporary.wav'))\n",
    "\n",
    "# Last step\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nficano/pytube\n",
    "import pytube\n",
    "\n",
    "print(\"Enter YouTube video url: \")\n",
    "url = str(input())\n",
    "\n",
    "try:\n",
    "    ytd = pytube.YouTube(url)\n",
    "    print('\\nVideo Title:')\n",
    "    print(ytd.title)\n",
    "    print(\"\\n..Downloading..\")\n",
    "    ytd = pytube.YouTube(url).streams.filter(only_audio=True).first().download('./input')\n",
    "    print('\\n # Done # ')\n",
    "\n",
    "except pytube.exceptions.RegexMatchError as e:\n",
    "    print('Error : {}'.format(e))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
