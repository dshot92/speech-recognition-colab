{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import time # for delay\n",
    "import json\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from os import listdir\n",
    "from wit import Wit\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to transcribe\n",
    "path = './input/'\n",
    "source_file = 'smith.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Setups\n",
    "\n",
    "# Getting audiofile\n",
    "audio = AudioSegment.from_wav(path + source_file)\n",
    "\n",
    "# SpeechRecognition initialization\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Creates files of 15 seconds (works best for speechdetection)\n",
    "offset = 15000 # millisecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google APIs\n",
    "\n",
    "for j in range(len(audio) / offset):\n",
    "    t1 = j * offset #Works in milliseconds\n",
    "    t2 = t1 + offset\n",
    "    \n",
    "    audio_segment = audio[t1:t2]\n",
    "    audio_segment.export('./aux.wav', format=\"wav\")\n",
    "    \n",
    "    try:\n",
    "        with sr.AudioFile('./aux.wav') as source:\n",
    "            aux = r.record(source)  # read the entire audio file\n",
    "\n",
    "        data = r.recognize_google(aux, language=\"en-US\", show_all=False)\n",
    "        # file_object = open('./output/' + source_file + '_google.txt', 'a')\n",
    "        # file_object.write(str(data))\n",
    "        # file_object.close()\n",
    "        print(str(data))\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wit.AI APIs\n",
    "\n",
    "# authentication\n",
    "access_token = 'NZ53DR2SUADO2PBLJONJI3H4OZZDB3AD'\n",
    "client = Wit(access_token)\n",
    "\n",
    "for j in range(len(audio) / offset):\n",
    "    t1 = j * offset #Works in milliseconds\n",
    "    t2 = t1 + offset\n",
    "    audio_segment = audio[t1:t2]\n",
    "    audio_segment.export('./aux.wav', format=\"wav\")\n",
    "\n",
    "    with open('./aux.wav', 'rb') as f:\n",
    "        resp = client.speech(f, {'Content-Type': 'audio/wav'})\n",
    "\n",
    "    # file_object = open('./output/' + source_file + '_witAI.txt', 'a')\n",
    "    # file_object.write(str(resp['text']))\n",
    "    # file_object.close()\n",
    "    print(str(resp['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
