{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598088318194",
   "display_name": "Python 3.8.5 64-bit ('data_science': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/nficano/pytube\n",
    "import os\n",
    "import pytube\n",
    "\n",
    "print(\"Enter YouTube video url: \")\n",
    "url = str(input())\n",
    "\n",
    "input_folder = os.path.join(os.getcwd(), \"input\")\n",
    "\n",
    "try:\n",
    "    ytd = pytube.YouTube(url)\n",
    "    print('\\nVideo Title:')\n",
    "    name = ytd.title\n",
    "    print(ytd.title)\n",
    "    print(\"\\n..Downloading..\")\n",
    "    ytd = pytube.YouTube(url).streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first().download(input_folder)\n",
    "    print('\\n # Done # ')\n",
    "\n",
    "except pytube.exceptions.RegexMatchError as e:\n",
    "    print('Error : {}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import time # for delay\n",
    "import datetime\n",
    "import speech_recognition as sr\n",
    "from os import listdir\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# get list of file in input folder\n",
    "path_input = os.getcwd() + os.sep +  'input'\n",
    "path_output = os.getcwd() + os.sep +  'output'\n",
    "\n",
    "# pydub.AudioSegment.ffmpeg = \"C:/ffmpeg\"\n",
    "\n",
    "list = os.listdir(path_input)\n",
    "if len(list) < 1 :\n",
    "    print('No files to transcribe!')\n",
    "    sys.exit()\n",
    "\n",
    "# list of file in input folder\n",
    "print('\\nSelect file to transcribe: ')\n",
    "for i in range(len(list)):\n",
    "    print(str(i) + ' : ' + list[i])\n",
    "\n",
    "#get input from userÃ²\n",
    "file_name = int(input())\n",
    "\n",
    "file_name = list[file_name]\n",
    "\n",
    "# get audiofile into usable form\n",
    "audio = AudioSegment.from_file(os.path.join(path_input, str(file_name)))\n",
    "offset = 3000 # 15000 == 15 seconds -- calculate in millisecond\n",
    "\n",
    "# initialize recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Languages List\n",
    "# http://www.lingoes.net/en/translator/langcode.htm\n",
    "\n",
    "languages = ['en-US', 'it-IT']\n",
    "print('\\nSelect language transcribing:')\n",
    "for j in range(len(languages)):\n",
    "    print('{} : {}'.format(j, languages[j]))\n",
    "language = int(input())\n",
    "language = languages[language]\n",
    "\n",
    "parts = 1 + (len(audio) // offset)\n",
    "for j in range(parts):\n",
    "    # get intervals of 15 from audio data\n",
    "    t1 = j * offset\n",
    "    t2 = t1 + offset\n",
    "    audio_segment = audio[t1:t2 + 1000]\n",
    "\n",
    "    audio_segment.export(os.path.join(path_input, 'temporary.wav') , format=\"wav\")\n",
    "\n",
    "    start = str(datetime.timedelta(seconds=t1 / 1000))\n",
    "    end = str(datetime.timedelta(seconds=t2 / 1000))\n",
    "    print('Part {} of {} \\t [ {}s : {}s ]'.format(j+1,parts, start,end ))\n",
    "    try:\n",
    "        with sr.AudioFile( os.path.join(path_input, 'temporary.wav')) as source:\n",
    "            aux = r.record(source)  # read the entire audio file\n",
    "\n",
    "        # call to google APIs\n",
    "        data = r.recognize_google(aux, language=language, show_all=False) # English\n",
    "\n",
    "        file_object = open(os.path.join(path_output, file_name) + '_google.txt' , 'a')\n",
    "        file_object.write('\\n[ ' + str(datetime.timedelta(seconds=t1 / 1000)) + 's : ' + str(datetime.timedelta(seconds=t2 / 1000)) + 's ]\\n')\n",
    "        if str(data)[-1] == ' ':\n",
    "            file_object.write(str(data))\n",
    "        else:\n",
    "            file_object.write(str(data) + ' ')\n",
    "        file_object.close()\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "    #delete aux files of 15 seconds\n",
    "    os.remove(os.path.join(path_input, 'temporary.wav'))\n",
    "# Last step\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18625085/how-to-plot-a-wav-file\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read audio samples\n",
    "path_input = os.getcwd() + os.sep +  'input'\n",
    "file_name = os.path.join(path_input, 'temporary.wav')\n",
    "input_data = read(file_name)\n",
    "audio = input_data[1]\n",
    "\n",
    "# plot the first 1024 samples\n",
    "plt.plot(audio[0:1024])\n",
    "\n",
    "# label the axes\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "# set the title  \n",
    "plt.title(\"Sample Wav\")\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18625085/how-to-plot-a-wav-file\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_input = os.getcwd() + os.sep +  'input'\n",
    "file_name = os.path.join(path_input, 'temporary.wav')   \n",
    "\n",
    "signal_wave = wave.open(file_name, 'r')\n",
    "sample_rate = 16000\n",
    "sig = np.frombuffer(signal_wave.readframes(sample_rate), dtype=np.int16)\n",
    "\n",
    "###For the whole segment of the wave file\n",
    "# sig = sig[:]\n",
    "\n",
    "### For partial segment of the wave file\n",
    "sig = sig[1:102400]\n",
    "\n",
    "### Separating stereo channels\n",
    "left, right = sig[0::2], sig[1::2]\n",
    "\n",
    "### Plot the waveform (plot_a) and the frequency spectrum (plot_b)\n",
    "plt.figure(1)\n",
    "\n",
    "plot_a = plt.subplot(211)\n",
    "plot_a.plot(sig)\n",
    "plot_a.set_xlabel('sample rate * time')\n",
    "plot_a.set_ylabel('energy')\n",
    "\n",
    "plot_b = plt.subplot(212)\n",
    "plot_b.specgram(sig, NFFT=1024, Fs=sample_rate, noverlap=900)\n",
    "plot_b.set_xlabel('Time')\n",
    "plot_b.set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}